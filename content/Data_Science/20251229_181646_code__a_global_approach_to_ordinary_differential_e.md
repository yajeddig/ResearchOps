---
title: "CODE: A Global Approach to Ordinary Differential Equation (ODE) Dynamics Learning with Polynomial Chaos Expansion"
date: 2025-12-29
category: Data_Science
confidence: 0.95
tags: ['ODE learning', 'ChaosODE', 'NeuralODE', 'KernelODE', 'Polynomial Chaos Expansion', 'Data-driven modeling', 'Extrapolation', 'Generalization', 'Sparse data', 'Noisy data', 'Optimization', 'Dynamical systems', 'Machine learning']
source: "Telegram Document"
type: Article
source_type: Article
hash: 181646
---

### üéØ Relevance
This research is highly useful for industrial data science applications where dynamic systems (e.g., chemical reactors, biological processes, environmental models) need to be modeled from limited and noisy sensor data. Improved extrapolation and generalization capabilities mean more reliable predictive models for process control, optimization, and anomaly detection, leading to better operational efficiency and reduced risks. It offers a learning opportunity for practitioners to understand the importance of model structure in data-driven modeling beyond generic machine learning approaches.

### üìù Summary
- **Key Message:** Introduces ChaosODE (CODE), a novel data-driven method using orthonormal polynomial chaos expansion to learn ODE dynamics, demonstrating superior extrapolation and generalization compared to NeuralODE and KernelODE, especially with scarce and noisy data.
- **Data/Statistics Mentioned:** Evaluated on the Lotka-Volterra predator-prey system. Performance metrics include Mean Squared Error (MSE) for in-training (ex-it), temporal extrapolation (ex-oot), and out-of-distribution generalization (ex-ood). Experiments involved varying data points (10 to 500) and noise levels (œÉ from 0.0 to 1.0).
- **Insights:** CODE achieves high precision (e.g., ex-it MSE of 1.23 √ó 10^-6) and strong generalization (ex-ood MSE of 0.0119) due to its polynomial basis matching the underlying dynamics. NeuralODE and KernelODE exhibit local overfitting and poor extrapolation with scarce/noisy data. The orthonormal basis in CODE significantly improves learning efficiency and reduces computational cost.
- **Actionable Takeaways:** For data-driven learning of ODE dynamics, selecting a problem-tailored RHS basis (like polynomial chaos for systems with polynomial dynamics) is crucial for robust extrapolation and generalization, especially when data is limited or noisy. This challenges the default use of highly flexible models like NeuralODEs without considering underlying system structure.

### üìÑ Extracted Content
Ordinary differential equations (ODEs) are a conventional way to describe the observed dynamics of physical systems. Scientists typically hypothesize about dynamical behavior, propose a mathematical model, and compare its predictions to data. However, modern computing and algorithmic advances now enable purely data-driven learning of governing dynamics directly from observations.
In data-driven settings, one learns the ODE's right-hand side (RHS). Dense measurements are often assumed, yet high temporal resolution is typically both cumbersome and expensive. Consequently, one usually has only sparsely sampled data. In this work we introduce ChaosODE (CODE), a Polynomial Chaos ODE Expansion in which we use an arbitrary Polynomial Chaos Expansion (aPCE) for the ODE's right-hand side, resulting in a global orthonormal polynomial representation of dynamics. We evaluate the performance of CODE in several experiments on the Lotka-Volterra system, across varying noise levels, initial conditions, and predictions far into the future, even on previously unseen initial conditions. CODE exhibits remarkable extrapolation capabilities even when evaluated under novel initial conditions and shows advantages compared to well-examined methods using neural networks (NeuralODE) or kernel approximators (KernelODE) as the RHS representer. We observe that the high flexibility of NeuralODE and KernelODE degrades extrapolation capabilities under scarce data and measurement noise.
This research challenges the common practice of using NeuralODE as a default for autonomous continuous-time UDE learning, advocating instead for architectural decisions informed by problem structure. We highlight that the selection of the RHS basis should align with the system dynamics, as it implicitly introduces inductive bias.

### üè∑Ô∏è Classification Reason
The document focuses on advanced data-driven modeling techniques (ML, statistical modeling, optimization) for learning Ordinary Differential Equation (ODE) dynamics, which is a core topic within the Data Science category.
